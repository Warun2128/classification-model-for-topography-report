{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries if needed\n",
        "# !pip install pandas scikit-learn numpy matplotlib\n",
        "\n",
        "import json, re, os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "\n",
        "import pickle\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "DETAILED_DATA = Path('./synthetic_fire_dataset_detailed.jsonl')\n",
        "ARTIFACTS_DIR = Path('artifacts')\n",
        "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
        "print('Artifacts will be saved to:', ARTIFACTS_DIR.resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouCHNOPPuP20",
        "outputId": "2fedde63-7578-4964-999f-02e3796d95b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifacts will be saved to: /content/artifacts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json, re, os\n",
        "import pandas as pd\n",
        "\n",
        "DETAILED_DATA = Path('./synthetic_fire_dataset_detailed.jsonl')\n",
        "\n",
        "def load_jsonl(path: Path):\n",
        "    rows = []\n",
        "    with open(path, 'r') as f:\n",
        "        for line in f:\n",
        "            rows.append(json.loads(line))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "df = load_jsonl(DETAILED_DATA)\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkMTCcv4uRh4",
        "outputId": "0051a294-ff9e-4173-eb30-5b58d69271db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['instruction', 'output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Import numpy here\n",
        "\n",
        "def parse_elevation_range(s: str):\n",
        "    if not isinstance(s, str):\n",
        "        return np.nan, np.nan, np.nan\n",
        "    m = re.match(r'\\s*(\\d+)\\s*-\\s*(\\d+)\\s*', s)\n",
        "    if not m:\n",
        "        return np.nan, np.nan, np.nan\n",
        "    low = int(m.group(1))\n",
        "    high = int(m.group(2))\n",
        "    return low, high, high - low\n",
        "\n",
        "def parse_density(s: str):\n",
        "    if not isinstance(s, str):\n",
        "        return np.nan\n",
        "    m = re.match(r'\\s*(\\d+)\\s*kg/acre\\s*', s)\n",
        "    if not m:\n",
        "        return np.nan\n",
        "    return float(m.group(1))\n",
        "\n",
        "def most_frequent_slope(slopes):\n",
        "    if not isinstance(slopes, list) or len(slopes) == 0:\n",
        "        return None\n",
        "    def norm(lbl):\n",
        "        if not isinstance(lbl, str): return None\n",
        "        if 'Flat' in lbl: return 'Flat'\n",
        "        if 'Moderate' in lbl: return 'Moderate'\n",
        "        if 'Steep' in lbl: return 'Steep'\n",
        "        return lbl\n",
        "    normed = [norm(s) for s in slopes if s]\n",
        "    if not normed: return None\n",
        "    vals, counts = np.unique(normed, return_counts=True)\n",
        "    return vals[counts.argmax()]\n",
        "\n",
        "records = []\n",
        "for i, row in df.iterrows():\n",
        "    instr = row.get('instruction', {})\n",
        "    outp = row.get('output', {})\n",
        "    if not isinstance(instr, dict) or not isinstance(outp, dict):\n",
        "        continue\n",
        "    topo_report = instr.get('topography_report', {})\n",
        "    label = topo_report.get('terrain_type', None)\n",
        "    text = outp.get('disaster_analysis', None)\n",
        "    if not (label and text):\n",
        "        continue\n",
        "    avg_slope_deg = topo_report.get('average_slope_degree', np.nan)\n",
        "    elev_low, elev_high, elev_diff = parse_elevation_range(topo_report.get('elevation_range_ft', None))\n",
        "    fuel_density = parse_density(topo_report.get('avg_fuel_density', None))\n",
        "    slope_mode = most_frequent_slope(topo_report.get('mpr_slopes', []))\n",
        "    records.append({\n",
        "        'text': text,\n",
        "        'terrain_type': label,\n",
        "        'average_slope_degree': avg_slope_deg,\n",
        "        'elev_low_ft': elev_low,\n",
        "        'elev_high_ft': elev_high,\n",
        "        'elev_diff_ft': elev_diff,\n",
        "        'fuel_density_kg_per_acre': fuel_density,\n",
        "        'slope_mode': slope_mode,\n",
        "    })\n",
        "\n",
        "data = pd.DataFrame(records)"
      ],
      "metadata": {
        "id": "MCCDhqinuUC3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = sorted(data['terrain_type'].dropna().unique().tolist())\n",
        "label_file = ARTIFACTS_DIR / 'topography_labels_detailed.txt'\n",
        "with open(label_file, 'w') as f:\n",
        "    for lab in labels:\n",
        "        f.write(lab + '\\n')\n",
        "print('Saved labels to:', label_file.resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-57GVvpFuXlk",
        "outputId": "e0ed0e62-c99d-405a-8b66-fcb6345818ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved labels to: /content/artifacts/topography_labels_detailed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_text = data[['text']].copy()\n",
        "y = data['terrain_type']\n",
        "\n",
        "X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
        "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "baseline = Pipeline(steps=[\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=2)),\n",
        "    ('clf', LogisticRegression(max_iter=1500, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "baseline.fit(X_train_txt['text'], y_train)\n",
        "y_pred_base = baseline.predict(X_test_txt['text'])\n",
        "\n",
        "print('Baseline Accuracy:', accuracy_score(y_test, y_pred_base))\n",
        "print('\\nClassification Report (Baseline):\\n')\n",
        "print(classification_report(y_test, y_pred_base, digits=3))\n",
        "\n",
        "# Save baseline model\n",
        "with open(ARTIFACTS_DIR / 'baseline_text_model.pkl', 'wb') as f:\n",
        "    pickle.dump(baseline, f)\n",
        "print('Saved baseline model to:', (ARTIFACTS_DIR / 'baseline_text_model.pkl').resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV6Dj-4mubqS",
        "outputId": "11211d38-8492-43ae-e189-152c85524e95"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 0.25\n",
            "\n",
            "Classification Report (Baseline):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Canyon      0.250     1.000     0.400         5\n",
            "    Flatland      0.000     0.000     0.000         6\n",
            "       Hills      0.000     0.000     0.000         5\n",
            "       Ridge      0.000     0.000     0.000         4\n",
            "\n",
            "    accuracy                          0.250        20\n",
            "   macro avg      0.062     0.250     0.100        20\n",
            "weighted avg      0.062     0.250     0.100        20\n",
            "\n",
            "Saved baseline model to: /content/artifacts/baseline_text_model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "ARTIFACTS_DIR = Path('artifacts')\n",
        "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "X = data[['text', 'average_slope_degree', 'elev_low_ft', 'elev_high_ft', 'elev_diff_ft', 'fuel_density_kg_per_acre', 'slope_mode']].copy()\n",
        "y = data['terrain_type']\n",
        "\n",
        "text_col = 'text'\n",
        "num_cols = ['average_slope_degree', 'elev_low_ft', 'elev_high_ft', 'elev_diff_ft', 'fuel_density_kg_per_acre']\n",
        "cat_cols = ['slope_mode']\n",
        "\n",
        "preproc = ColumnTransformer(transformers=[\n",
        "    ('text', TfidfVectorizer(max_features=7000, ngram_range=(1,2), min_df=2), text_col),\n",
        "    ('num', StandardScaler(with_mean=False), num_cols), # with_mean=False for sparse safety\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "])\n",
        "\n",
        "hybrid = Pipeline(steps=[\n",
        "    ('prep', preproc),\n",
        "    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=7, stratify=y\n",
        ")\n",
        "\n",
        "hybrid.fit(X_train, y_train)\n",
        "y_pred_h = hybrid.predict(X_test)\n",
        "\n",
        "print('Hybrid Accuracy:', accuracy_score(y_test, y_pred_h))\n",
        "print('\\nClassification Report (Hybrid):\\n')\n",
        "print(classification_report(y_test, y_pred_h, digits=3))\n",
        "\n",
        "# Save hybrid model\n",
        "with open(ARTIFACTS_DIR / 'hybrid_model.pkl', 'wb') as f:\n",
        "    pickle.dump(hybrid, f)\n",
        "print('Saved hybrid model to:', (ARTIFACTS_DIR / 'hybrid_model.pkl').resolve())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPlfDTDeuefr",
        "outputId": "b77b06dd-3ba3-4a97-a8f7-4b413936a16f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hybrid Accuracy: 0.4\n",
            "\n",
            "Classification Report (Hybrid):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Canyon      0.429     0.600     0.500         5\n",
            "    Flatland      0.400     0.400     0.400         5\n",
            "       Hills      0.333     0.333     0.333         6\n",
            "       Ridge      0.500     0.250     0.333         4\n",
            "\n",
            "    accuracy                          0.400        20\n",
            "   macro avg      0.415     0.396     0.392        20\n",
            "weighted avg      0.407     0.400     0.392        20\n",
            "\n",
            "Saved hybrid model to: /content/artifacts/hybrid_model.pkl\n"
          ]
        }
      ]
    }
  ]
}